# app.py
# å½“è½äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆSHAP çµ±åˆç‰ˆï¼‰
import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
import os
import io
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import LabelEncoder
from category_encoders import CatBoostEncoder
import lightgbm as lgb
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib

# SHAP ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ç’°å¢ƒã§ã‚‚å‹•ãã‚ˆã† try/exceptï¼‰
try:
    import shap
    SHAP_AVAILABLE = True
except Exception:
    SHAP_AVAILABLE = False

plt.rcParams["font.family"] = "MS Gothic"
sns.set_style("whitegrid")
shap_option = st.sidebar.checkbox("SHAPã‚’è¡¨ç¤ºã™ã‚‹")


# ---------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------
@st.cache_data
def load_excel(uploaded):
    return pd.read_excel(uploaded, engine="openpyxl")

def safe_rename(df):
    df = df.copy()
    df.columns = df.columns.str.strip()
    rename_dict = {
        "è¡†å‚ã™ã¹ã¦ã®å½“é¸å›æ•°": "è¡†å‚å½“é¸å›æ•°",
        "å‚è­°é™¢ã®å½“é¸å›æ•°": "å‚è­°é™¢å½“é¸å›æ•°",
        "è¡†è­°é™¢ã®å½“é¸å›æ•°": "è¡†è­°é™¢å½“é¸å›æ•°",
        "å¤§ããªæ”¿åºœã‹å°ã•ãªæ”¿åºœã‹(1ã«è¿‘ã„ã»ã©å°ã•ãªæ”¿åºœ/5ã«è¿‘ã„ã»ã©å¤§ããªæ”¿åºœ)": "æ”¿åºœè¦æ¨¡",
        "å‡ºç”Ÿåœ°ã‹ã‚‰ã®ç«‹å€™è£œã‹(0ãŒå‡ºç”Ÿåœ°ã‹ã‚‰ç«‹å€™è£œã€1ãŒå‡ºç”Ÿåœ°ã‹ã‚‰ç«‹å€™è£œã§ã¯ãªã„)": "å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°",
        "ç§˜æ›¸çµŒé¨“ã®æœ‰ç„¡(0ãŒç§˜æ›¸çµŒé¨“ã‚ã‚Šã€1ãŒç§˜æ›¸çµŒé¨“ãªã—)": "ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°",
        "åœ°æ–¹è­°ä¼šçµŒé¨“ã®æœ‰ç„¡(0ãŒåœ°æ–¹è­°ä¼šçµŒé¨“ã‚ã‚Šã€1ãŒåœ°æ–¹è­°ä¼šçµŒé¨“ãªã—)": "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°"
    }
    for k, v in rename_dict.items():
        if k in df.columns:
            df = df.rename(columns={k: v})
    return df

def coerce_target_series(y):
    if pd.api.types.is_numeric_dtype(y):
        return y.astype(float)
    y_ser = y.fillna("").astype(str).str.strip()
    mapping = {
        "å½“é¸": 1, "è½é¸": 0, "å½“": 1, "è½": 0,
        "åˆæ ¼": 1, "ä¸åˆæ ¼": 0,
        "win": 1, "lose": 0, "W": 1, "L": 0,
        "True": 1, "False": 0, "true": 1, "false": 0
    }
    mapped = y_ser.map(mapping)
    if mapped.notnull().all():
        return mapped.astype(float)
    def try_numeric(val):
        try:
            return float(val)
        except:
            return np.nan
    numeric_candidate = y_ser.map(try_numeric)
    combined = mapped.copy()
    combined[pd.isna(combined)] = numeric_candidate[pd.isna(combined)]
    if combined.notnull().all():
        return combined.astype(float)
    le = LabelEncoder()
    try:
        encoded = le.fit_transform(y_ser)
        return pd.Series(encoded.astype(float), index=y_ser.index)
    except Exception:
        raise ValueError("ç›®çš„å¤‰æ•°ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'å½“é¸/è½é¸' ãªã©ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚")

def prepare_label_encoders(df, label_cols):
    encoders = {}
    for col in label_cols:
        if col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                continue
            le = LabelEncoder()
            df[col] = df[col].fillna("nan").astype(str)
            df[col] = le.fit_transform(df[col])
            encoders[col] = le
    return df, encoders

def apply_cbe_kfold(X, y, label_cols, n_splits=5, random_state=42):
    X = X.copy().reset_index(drop=True)
    y = y.reset_index(drop=True)
    valid_label_cols = [c for c in label_cols if c in X.columns]
    if len(valid_label_cols) == 0:
        return X, None
    cbe = CatBoostEncoder()
    kf = KFold(n_splits=max(2, int(n_splits)), shuffle=True, random_state=random_state)
    X_cbe = np.zeros((len(X), len(valid_label_cols)))
    for tr_idx, va_idx in kf.split(X):
        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
        y_tr = y.iloc[tr_idx]
        cbe.fit(X_tr[valid_label_cols], y_tr)
        transformed = cbe.transform(X_va[valid_label_cols])
        X_cbe[va_idx, :] = transformed.values
    cbe.fit(X[valid_label_cols], y)
    for i, col in enumerate(valid_label_cols):
        X[f"{col}_cbe"] = X_cbe[:, i]
    return X, cbe

# ---------------------------
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€
# ---------------------------
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# ---------------------------
# UIè¨­å®š
# ---------------------------
st.set_page_config(layout="wide", page_title="å½“è½äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (SHAP çµ±åˆ)")
st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    ["Overview", "Train Model", "Candidate Prediction",
     "Party / Region Analysis", "Feature Analysis", "Model Management"]
)

# ---------------------------
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ---------------------------
st.sidebar.write("---")
uploaded_file = st.sidebar.file_uploader(
    "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["xlsx"],
    key="excel_uploader_sidebar"
)
df = None
if uploaded_file is not None:
    df = load_excel(uploaded_file)
    df = safe_rename(df)
    if "å½“è½" in df.columns:
        try:
            df["å½“è½"] = coerce_target_series(df["å½“è½"])
        except Exception as e:
            st.error(f"ç›®çš„å¤‰æ•° 'å½“è½' ã‚’æ•°å€¤åŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

# ---------------------------
# Overview
# ---------------------------
if page == "Overview":
    st.title("Overview â€” ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
    if df is None:
        st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df.head())
        st.write("å½¢çŠ¶:", df.shape)
        st.subheader("çµ±è¨ˆæ¦‚è¦ï¼ˆæ•°å€¤åˆ—ï¼‰")
        st.dataframe(df.describe())
        st.subheader("æ¬ æå€¤ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯")
        miss = df.isnull().sum().sort_values(ascending=False).head(20)
        st.dataframe(miss[miss > 0])

# ---------------------------
# Train Model
# ---------------------------
elif page == "Train Model":
    st.title("Train Model â€” ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆSHAP ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ã“ã¡ã‚‰ã§å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        # Label åˆ—å€™è£œ
        label_cols = [
            c for c in [
                "å…šæ´¾", "å…ƒç¾æ–°", "äº‰ç‚¹1ä½", "äº‰ç‚¹2ä½", "äº‰ç‚¹3ä½",
                "è·æ¥­(åˆ†é¡)", "å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°",
                "ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°", "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°"
            ]
            if c in df.columns
        ]

        # ç›®çš„å¤‰æ•°é¸æŠ
        if "å½“è½" in df.columns:
            default_index = list(df.columns).index("å½“è½")
        else:
            default_index = 0

        target_col = st.sidebar.selectbox(
            "ç›®çš„å¤‰æ•°ã‚’é¸æŠ",
            options=[c for c in df.columns],
            index=default_index
        )
        st.write("ç›®çš„å¤‰æ•°:", target_col)

        # ã€Œæ–°äººã®ã¿ã€ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
        filter_new = False
        if "å…ƒç¾æ–°" in df.columns:
            filter_new = st.sidebar.checkbox("æ–°äººã®ã¿ã§å­¦ç¿’ã™ã‚‹ (å…ƒç¾æ–° == 'æ–°')", value=False)

        # ç‰¹å¾´é‡é¸æŠ
        features = st.multiselect(
            "ç‰¹å¾´é‡ã‚’é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å¥¨ï¼‰",
            options=[c for c in df.columns if c != target_col],
            default=[c for c in [
                "å¹´é½¢","æ€§åˆ¥","å…šæ´¾","å…ƒç¾æ–°","è¡†å‚å½“é¸å›æ•°","å‚è­°é™¢å½“é¸å›æ•°",
                "è¡†è­°é™¢å½“é¸å›æ•°","è­°å¸­æ•°","äº‰ç‚¹1ä½","äº‰ç‚¹2ä½","äº‰ç‚¹3ä½",
                "æ”¿åºœè¦æ¨¡","å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°","ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°",
                "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°","è·æ¥­(åˆ†é¡)"
            ] if c in df.columns]
        )

        test_size = st.sidebar.slider("æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å‰²åˆï¼ˆtest_sizeï¼‰", 0.1, 0.5, 0.2)

        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        st.sidebar.write("LightGBM ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        lr = st.sidebar.number_input("learning_rate", min_value=0.0001, max_value=0.5,
                                     value=0.05, format="%.4f")
        num_leaves = st.sidebar.slider("num_leaves", 8, 512, 64)
        n_estimators = st.sidebar.number_input(
            "num_boost_round æœ€å¤§",
            min_value=100, max_value=100000,
            value=5000, step=100
        )
        early_stopping_rounds = st.sidebar.number_input(
            "early_stopping_rounds",
            min_value=10, max_value=1000, value=100
        )
        val_frac_for_cbe = st.sidebar.slider("CBE ç”¨ kfold åˆ†å‰²æ•°", 3, 10, 5)

        # SHAP æœ‰ç„¡ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ã®ã§æ˜ç¤ºçš„ã«ï¼‰
        shap_option = False
        if SHAP_AVAILABLE:
            shap_option = st.sidebar.checkbox("å­¦ç¿’å¾Œã« SHAP ã‚’è¨ˆç®—ãƒ»è¡¨ç¤ºã™ã‚‹ï¼ˆè¨ˆç®—è² è·ã‚ã‚Šï¼‰", value=False)
        else:
            st.sidebar.write("SHAP ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚requirements.txt ã« 'shap' ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

        if st.button("å‰å‡¦ç†ï¼†å­¦ç¿’ã‚’å®Ÿè¡Œ"):
            with st.spinner("å‰å‡¦ç†ä¸­..."):
                df_train = df.copy()
                if filter_new:
                    if "å…ƒç¾æ–°" in df_train.columns:
                        df_train = df_train[df_train["å…ƒç¾æ–°"].astype(str).str.strip() == "æ–°"].copy()
                        if df_train.empty:
                            st.error("æ–°äººãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                            st.stop()
                    else:
                        st.error("'å…ƒç¾æ–°' åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                        st.stop()

                X = df_train[features].copy()
                y = df_train[target_col].copy()

                try:
                    y = coerce_target_series(y)
                except Exception as e:
                    st.error(f"ç›®çš„å¤‰æ•°ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    st.stop()

                # LabelEncoder é©ç”¨
                X, encoders = prepare_label_encoders(X, label_cols)

                # CBE
                X, cbe = apply_cbe_kfold(X, y, label_cols, n_splits=val_frac_for_cbe)

                features_used = X.columns.tolist()

                try:
                    X_train, X_val, y_train, y_val = train_test_split(
                        X, y, test_size=test_size, stratify=y, random_state=42
                    )
                except Exception as e:
                    st.error(f"train_test_split ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆstratify å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼‰: {e}")
                    st.stop()

                train_data = lgb.Dataset(X_train, label=y_train)
                valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

                params = {
                    "objective": "binary",
                    "metric": "binary_logloss",
                    "learning_rate": 0.01,
                    "num_leaves": 255,     # æœ¨ã®å®¹é‡æœ€å¤§
                    "max_depth": -1,       # æ·±ã•åˆ¶é™ãªã—
                    "min_data_in_leaf": 1, # è‘‰1ã‚µãƒ³ãƒ—ãƒ«ã§æŸ”è»Ÿã«
                    "feature_fraction": 1.0,
                    "bagging_fraction": 1.0,
                    "bagging_freq": 0,
                    "lambda_l1": 0.0,
                    "lambda_l2": 0.0,
                    "class_weight": None,
                    "verbose": -1,
                    "seed": 42
                }

            with st.spinner("LightGBM å­¦ç¿’ä¸­..."):
                model = lgb.train(
                    params,
                    train_data,
                     num_boost_round=50000,
                )

            # è©•ä¾¡è¡¨ç¤º
            y_val_pred_prob = model.predict(X_val)
            y_val_pred = (y_val_pred_prob >= 0.5).astype(int)
            st.subheader("è©•ä¾¡ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
            st.write("æ··åŒè¡Œåˆ—")
            st.write(confusion_matrix(y_val, y_val_pred))
            st.write({
                "Accuracy": accuracy_score(y_val, y_val_pred),
                "Precision": precision_score(y_val, y_val_pred, zero_division=0),
                "Recall": recall_score(y_val, y_val_pred, zero_division=0),
                "F1": f1_score(y_val, y_val_pred, zero_division=0),
                "ROC_AUC": roc_auc_score(y_val, y_val_pred_prob)
            })

            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            model_name = f"lgb_model_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            save_obj = {
                "model": model,
                "features": features_used,
                "cbe": cbe,
                "label_cols": label_cols,
                "label_encoders": encoders
            }
            joblib.dump(save_obj, os.path.join(MODEL_DIR, model_name))
            st.success(f"å­¦ç¿’å®Œäº†ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_name}")
            st.session_state["latest_model_path"] = os.path.join(MODEL_DIR, model_name)

 # -----------------------
# SHAP è¨ˆç®—ï¼†è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# -----------------------
if shap_option and SHAP_AVAILABLE:
    with st.spinner("SHAP ã‚’è¨ˆç®—ä¸­ï¼ˆãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚Šæ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼‰..."):
        try:
            # X_val ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå¤§ãã„å ´åˆã¯ 500 è¡Œã«åˆ¶é™ï¼‰
            max_shap = 500
            if len(X_val) > max_shap:
                X_shap = X_val.sample(n=max_shap, random_state=42)
                st.write(f"SHAP ã¯ã‚µãƒ³ãƒ—ãƒ« {max_shap} è¡Œã§è¨ˆç®—ã—ã¾ã™ï¼ˆè¡¨ç¤ºã¯ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
            else:
                X_shap = X_val

            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_shap)
            # shap_values ã®å‹ã¯ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å¤‰ã‚ã‚‹å ´åˆãŒã‚ã‚‹ã€‚ndarray ã«æƒãˆã‚‹
            if isinstance(shap_values, list):
                shap_vals_for_plot = shap_values[0]
            else:
                shap_vals_for_plot = shap_values

            # ---------- Summary Plotï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰ ----------
            st.write("### SHAP Summary Plotï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰")
            # ä½™ç™½ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«å›³ã‚’å¤§ãã‚ã«ã—ã¦å·¦ãƒãƒ¼ã‚¸ãƒ³ã‚’åºƒã’ã‚‹
            fig_summary = plt.figure(figsize=(10, 6))
            shap.summary_plot(shap_vals_for_plot, X_shap, show=False)
            # é•·ã„ç‰¹å¾´åå¯¾ç­–ã«å·¦ãƒãƒ¼ã‚¸ãƒ³ã‚’æ‹¡å¼µï¼ˆæ—¥æœ¬èªãƒ©ãƒ™ãƒ«å‘ã‘ï¼‰
            try:
                fig_summary.tight_layout()
            except Exception:
                pass
            # çµŒé¨“å‰‡çš„ã«å·¦ã‚’åºƒã’ã‚‹ï¼ˆæ—¥æœ¬èªã®é•·ã„åˆ—åãŒåˆ‡ã‚Œã‚‹ã®ã‚’é˜²ãï¼‰
            try:
                fig_summary.subplots_adjust(left=0.35)
            except Exception:
                pass
            st.pyplot(fig_summary)
            plt.close(fig_summary)

            # ---------- Bar Plotï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰ ----------
            st.write("### SHAP Bar Plotï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰")
            # ç‰¹å¾´é‡æ•°ã«å¿œã˜ã¦ç¸¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼ˆå¤šã„ã»ã©ç¸¦é•·ã«ï¼‰
            n_features = X_shap.shape[1] if hasattr(X_shap, "shape") else len(X_shap.columns)
            height = max(4, min(0.35 * n_features, 20))  # ä¸Šé™ã‚’ã¤ã‘ã‚‹
            fig_bar = plt.figure(figsize=(10, height))
            shap.summary_plot(shap_vals_for_plot, X_shap, plot_type="bar", show=False)
            try:
                fig_bar.tight_layout()
            except Exception:
                pass
            try:
                fig_bar.subplots_adjust(left=0.35)
            except Exception:
                pass
            st.pyplot(fig_bar)
            plt.close(fig_bar)

        except Exception as e:
            st.error(f"SHAP è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


# ---------------------------
# Candidate Prediction
# ---------------------------
elif page == "Candidate Prediction":
    st.title("Candidate Prediction â€” æ–°è¦å€™è£œã®å½“è½äºˆæ¸¬ï¼ˆSHAP ã§è¦å› åˆ†æï¼‰")

    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pkl")]
    model_files.sort(reverse=True)
    selected_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆæœ€æ–°ã‚’é¸ã¶ï¼‰", options=model_files)

    if not selected_model:
        st.info("ã¾ã å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãš Train Model ã§å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    else:
        mdl = joblib.load(os.path.join(MODEL_DIR, selected_model))
        model = mdl["model"]
        features_used = mdl["features"]
        cbe = mdl.get("cbe", None)
        label_cols = mdl.get("label_cols", [])
        label_encoders = mdl.get("label_encoders", {})

        st.write("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«:", selected_model)
        st.write("å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«å€¤ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")

        input_data = {}
        for f in features_used:
            if f.endswith("_cbe"):
                continue
            if f in ["å¹´é½¢", "è¡†å‚å½“é¸å›æ•°", "å‚è­°é™¢å½“é¸å›æ•°", "è¡†è­°é™¢å½“é¸å›æ•°", "è­°å¸­æ•°", "æ”¿åºœè¦æ¨¡"]:
                input_data[f] = st.number_input(f, value=0)
            elif f in ["æ€§åˆ¥"]:
                input_data[f] = st.selectbox(f, options=[0, 1])
            else:
                input_data[f] = st.text_input(f, value="")

        shap_individual = False
        if SHAP_AVAILABLE:
            shap_individual = st.checkbox("ã“ã®å€™è£œè€…ã® SHAP force plot ã‚’è¡¨ç¤ºã™ã‚‹ (è¦ shap)", value=False)
        else:
            st.write("â€» SHAP ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å€‹åˆ¥è¦å› ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

        if st.button("äºˆæ¸¬ã™ã‚‹"):
            X_new = pd.DataFrame([input_data])

            # LabelEncoder é©ç”¨
            for col, le in label_encoders.items():
                if col in X_new.columns:
                    try:
                        X_new[col] = le.transform(X_new[col].fillna("nan").astype(str))
                    except Exception:
                        X_new[col] = 0

            # CBE ç‰¹å¾´ä½œæˆ
            if cbe is not None and label_cols:
                for col in label_cols:
                    if col in X_new.columns:
                        try:
                            transformed = cbe.transform(X_new[[col]])
                            X_new[f"{col}_cbe"] = transformed.iloc[:, 0]
                        except Exception:
                            X_new[f"{col}_cbe"] = 0
                    else:
                        X_new[f"{col}_cbe"] = 0

            # æ•´åˆ—
            X_new = X_new.reindex(columns=[c for c in features_used if not c.endswith("_cbe")] + [c for c in features_used if c.endswith("_cbe")], fill_value=0)
            X_new = X_new.reindex(columns=features_used, fill_value=0)

            try:
                prob_arr = model.predict(X_new)
                prob = float(prob_arr[0]) if hasattr(prob_arr, "__len__") else float(prob_arr)
            except Exception as e:
                st.error(f"ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.write("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰:")
                st.dataframe(X_new)
                st.stop()

            st.metric("å½“é¸ç¢ºç‡", f"{prob:.3f}")
            st.write("é–¾å€¤0.5åˆ¤å®š:", "å½“" if prob >= 0.5 else "è½")

            # å€‹åˆ¥ SHAP è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if shap_individual and SHAP_AVAILABLE:
                try:
                    explainer = shap.TreeExplainer(model)
                    shap_values = explainer.shap_values(X_new)
                    if isinstance(shap_values, list):
                        sv = shap_values[0]
                    else:
                        sv = shap_values

                    st.subheader("ã“ã®å€™è£œè€…ã® SHAP force plotï¼ˆè¦ HTML æç”»ï¼‰")
                    # force_plot ã‚’ HTML åŒ–ã—ã¦åŸ‹ã‚è¾¼ã‚€
                    force_html = shap.force_plot(explainer.expected_value, sv, X_new, matplotlib=False)
                    components.html(force_html.html(), height=300)
                except Exception as e:
                    st.error(f"å€‹åˆ¥ SHAP ã®ä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            elif shap_individual and not SHAP_AVAILABLE:
                st.warning("SHAP ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

# ---------------------------
# Party / Region Analysis
# ---------------------------
elif page == "Party / Region Analysis":
    st.title("Party / Region Analysis â€” æ”¿å…šãƒ»åœ°åŸŸã®é›†è¨ˆ")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        group_by = st.selectbox(
            "ã‚°ãƒ«ãƒ¼ãƒ—åŒ–",
            options=[c for c in ["å…šæ´¾", "è­°å¸­æ•°", "åœ°åŸŸ", "é¸æŒ™åŒº"] if c in df.columns]
        )
        if st.button("é›†è¨ˆå®Ÿè¡Œ"):
            try:
                summary = df.groupby(group_by).agg({"å½“è½": ["mean", "count"]})
                summary.columns = ["å½“é¸ç¢ºç‡", "å€™è£œæ•°"]
                summary = summary.sort_values("å½“é¸ç¢ºç‡", ascending=False)
                st.dataframe(summary.head(100))
                st.bar_chart(summary["å½“é¸ç¢ºç‡"])
            except Exception as e:
                st.error(f"é›†è¨ˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ---------------------------
# Feature Analysis
# ---------------------------
elif page == "Feature Analysis":
    st.title("Feature Analysis â€” ç‰¹å¾´é‡åˆ†æ")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("å˜å¤‰é‡åˆ†å¸ƒ")
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(num_cols) == 0:
            st.info("æ•°å€¤åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        else:
            choose = st.selectbox("æ•°å€¤åˆ—ã‚’é¸æŠ", options=num_cols)
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df[choose].dropna(), kde=True, ax=ax)
            st.pyplot(fig)

        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥å½“é¸ç‡")
        cat_cols = [c for c in df.columns if (df[c].dtype == object or df[c].nunique() < 30)]
        if len(cat_cols) == 0:
            st.info("ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            chosen_cat = st.selectbox("ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’é¸ã¶", options=cat_cols)
            try:
                agg = df.groupby(chosen_cat)["å½“è½"].mean().sort_values(ascending=False)
                st.dataframe(agg)
                st.bar_chart(agg)
            except Exception as e:
                st.error(f"ã‚«ãƒ†ã‚´ãƒªåˆ¥å½“é¸ç‡ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.write(df[chosen_cat].head())
                st.write(df["å½“è½"].dtype)
                st.write(df["å½“è½"].head())

# ---------------------------
# Model Management
# ---------------------------
elif page == "Model Management":
    st.title("Model Management â€” ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
    st.write("ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§")
    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pkl")]
    model_files.sort(reverse=True)
    st.dataframe(pd.DataFrame({"model": model_files}))
    sel = st.selectbox("æ“ä½œãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", options=[""] + model_files)
    if sel:
        path = os.path.join(MODEL_DIR, sel)
        st.write("ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹:", path)
        if st.button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            with open(path, "rb") as f:
                bytes_io = io.BytesIO(f.read())
            st.download_button("Download model", data=bytes_io, file_name=sel)
        if st.button("å‰Šé™¤"):
            os.remove(path)
            st.success("å‰Šé™¤ã—ã¾ã—ãŸã€‚å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
# ---------------------------
# Newcomer Winning Patterns
# ---------------------------
elif page == "Newcomer Winning Patterns":
    st.title("Newcomer Winning Patterns â€” æ–°äººã®å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")

    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # å…ƒç¾æ–°ãƒ•ã‚£ãƒ«ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if "å…ƒç¾æ–°" not in df.columns:
        st.error("ã“ã®åˆ†æã«ã¯ 'å…ƒç¾æ–°' åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        st.stop()

    # æ–°äººã ã‘æŠ½å‡º
    df_new = df[df["å…ƒç¾æ–°"].astype(str).str.strip() == "æ–°"].copy()
    if df_new.empty:
        st.error("æ–°äººãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    st.write(f"æ–°äººå€™è£œãƒ‡ãƒ¼ã‚¿æ•°: {len(df_new)} å")

    # åˆ†æå¯¾è±¡ã¨ãªã‚‹ã‚«ãƒ†ã‚´ãƒªåˆ—
    candidate_cols = [
        c for c in df_new.columns
        if (df_new[c].dtype == object or df_new[c].nunique() <= 20)
        and c not in ["å½“è½", "å…ƒç¾æ–°"]
    ]

    st.subheader("ç‰¹å¾´é‡ã”ã¨ã®æ–°äººå½“é¸ç‡ï¼ˆå˜å¤‰é‡ï¼‰")

    # å˜å¤‰é‡å½“é¸ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    result_list = []
    for col in candidate_cols:
        try:
            tmp = df_new.groupby(col)["å½“è½"].mean().sort_values(ascending=False)
            result_list.append((col, tmp))
        except:
            continue

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤º
    for col, series in result_list:
        st.markdown(f"### ğŸ“Œ {col} åˆ¥ å½“é¸ç‡")
        st.dataframe(series)
        st.bar_chart(series)

    st.write("---")

    # å¤šå¤‰é‡ã®å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ2å¤‰é‡çµ„ã¿åˆã‚ã›ï¼‰
    st.subheader("çµ„ã¿åˆã‚ã›å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤šå¤‰é‡ï¼š2ã¤ã®ç‰¹å¾´ï¼‰")

    top_k = st.slider("è¡¨ç¤ºã™ã‚‹ä¸Šä½ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°", 5, 50, 10)

    pattern_rows = []
    for col1 in candidate_cols:
        for col2 in candidate_cols:
            if col1 >= col2:
                continue
            try:
                grp = df_new.groupby([col1, col2])["å½“è½"].mean()
                grp = grp.reset_index().sort_values("å½“è½", ascending=False)
                pattern_rows.append((f"{col1} Ã— {col2}", grp.head(top_k)))
            except:
                pass

    # è¡¨ç¤ºï¼ˆå¤šã™ãã‚‹ã®ã§ 10çµ„ã¾ã§ï¼‰
    for title, patt in pattern_rows[:10]:
        st.markdown(f"### ğŸ”¥ {title} ã®å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆTop {top_k}ï¼‰")
        st.dataframe(patt)
# app.py
# å½“è½äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆSHAP çµ±åˆç‰ˆï¼‰
import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
import os
import io
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import LabelEncoder
from category_encoders import CatBoostEncoder
import lightgbm as lgb
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib

# SHAP ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ç’°å¢ƒã§ã‚‚å‹•ãã‚ˆã† try/exceptï¼‰
try:
    import shap
    SHAP_AVAILABLE = True
except Exception:
    SHAP_AVAILABLE = False

plt.rcParams["font.family"] = "MS Gothic"
sns.set_style("whitegrid")
shap_option = st.sidebar.checkbox("SHAPã‚’è¡¨ç¤ºã™ã‚‹", key="show_shap")


# ---------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------
@st.cache_data
def load_excel(uploaded):
    return pd.read_excel(uploaded, engine="openpyxl")

def safe_rename(df):
    df = df.copy()
    df.columns = df.columns.str.strip()
    rename_dict = {
        "è¡†å‚ã™ã¹ã¦ã®å½“é¸å›æ•°": "è¡†å‚å½“é¸å›æ•°",
        "å‚è­°é™¢ã®å½“é¸å›æ•°": "å‚è­°é™¢å½“é¸å›æ•°",
        "è¡†è­°é™¢ã®å½“é¸å›æ•°": "è¡†è­°é™¢å½“é¸å›æ•°",
        "å¤§ããªæ”¿åºœã‹å°ã•ãªæ”¿åºœã‹(1ã«è¿‘ã„ã»ã©å°ã•ãªæ”¿åºœ/5ã«è¿‘ã„ã»ã©å¤§ããªæ”¿åºœ)": "æ”¿åºœè¦æ¨¡",
        "å‡ºç”Ÿåœ°ã‹ã‚‰ã®ç«‹å€™è£œã‹(0ãŒå‡ºç”Ÿåœ°ã‹ã‚‰ç«‹å€™è£œã€1ãŒå‡ºç”Ÿåœ°ã‹ã‚‰ç«‹å€™è£œã§ã¯ãªã„)": "å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°",
        "ç§˜æ›¸çµŒé¨“ã®æœ‰ç„¡(0ãŒç§˜æ›¸çµŒé¨“ã‚ã‚Šã€1ãŒç§˜æ›¸çµŒé¨“ãªã—)": "ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°",
        "åœ°æ–¹è­°ä¼šçµŒé¨“ã®æœ‰ç„¡(0ãŒåœ°æ–¹è­°ä¼šçµŒé¨“ã‚ã‚Šã€1ãŒåœ°æ–¹è­°ä¼šçµŒé¨“ãªã—)": "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°"
    }
    for k, v in rename_dict.items():
        if k in df.columns:
            df = df.rename(columns={k: v})
    return df

def coerce_target_series(y):
    if pd.api.types.is_numeric_dtype(y):
        return y.astype(float)
    y_ser = y.fillna("").astype(str).str.strip()
    mapping = {
        "å½“é¸": 1, "è½é¸": 0, "å½“": 1, "è½": 0,
        "åˆæ ¼": 1, "ä¸åˆæ ¼": 0,
        "win": 1, "lose": 0, "W": 1, "L": 0,
        "True": 1, "False": 0, "true": 1, "false": 0
    }
    mapped = y_ser.map(mapping)
    if mapped.notnull().all():
        return mapped.astype(float)
    def try_numeric(val):
        try:
            return float(val)
        except:
            return np.nan
    numeric_candidate = y_ser.map(try_numeric)
    combined = mapped.copy()
    combined[pd.isna(combined)] = numeric_candidate[pd.isna(combined)]
    if combined.notnull().all():
        return combined.astype(float)
    le = LabelEncoder()
    try:
        encoded = le.fit_transform(y_ser)
        return pd.Series(encoded.astype(float), index=y_ser.index)
    except Exception:
        raise ValueError("ç›®çš„å¤‰æ•°ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'å½“é¸/è½é¸' ãªã©ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚")

def prepare_label_encoders(df, label_cols):
    encoders = {}
    for col in label_cols:
        if col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                continue
            le = LabelEncoder()
            df[col] = df[col].fillna("nan").astype(str)
            df[col] = le.fit_transform(df[col])
            encoders[col] = le
    return df, encoders

def apply_cbe_kfold(X, y, label_cols, n_splits=5, random_state=42):
    X = X.copy().reset_index(drop=True)
    y = y.reset_index(drop=True)
    valid_label_cols = [c for c in label_cols if c in X.columns]
    if len(valid_label_cols) == 0:
        return X, None
    cbe = CatBoostEncoder()
    kf = KFold(n_splits=max(2, int(n_splits)), shuffle=True, random_state=random_state)
    X_cbe = np.zeros((len(X), len(valid_label_cols)))
    for tr_idx, va_idx in kf.split(X):
        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
        y_tr = y.iloc[tr_idx]
        cbe.fit(X_tr[valid_label_cols], y_tr)
        transformed = cbe.transform(X_va[valid_label_cols])
        X_cbe[va_idx, :] = transformed.values
    cbe.fit(X[valid_label_cols], y)
    for i, col in enumerate(valid_label_cols):
        X[f"{col}_cbe"] = X_cbe[:, i]
    return X, cbe

# ---------------------------
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€
# ---------------------------
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# ---------------------------
# UIè¨­å®š
# ---------------------------
st.set_page_config(layout="wide", page_title="å½“è½äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (SHAP çµ±åˆ)")
st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    ["Overview", "Train Model", "Candidate Prediction",
     "Party / Region Analysis", "Feature Analysis", "Model Management"],
    key="page_select"
)

# ---------------------------
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ---------------------------
st.sidebar.write("---")
uploaded_file = st.sidebar.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
df = None
if uploaded_file is not None:
    df = load_excel(uploaded_file)
    df = safe_rename(df)
    if "å½“è½" in df.columns:
        try:
            df["å½“è½"] = coerce_target_series(df["å½“è½"])
        except Exception as e:
            st.error(f"ç›®çš„å¤‰æ•° 'å½“è½' ã‚’æ•°å€¤åŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

# ---------------------------
# Overview
# ---------------------------
if page == "Overview":
    st.title("Overview â€” ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
    if df is None:
        st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df.head())
        st.write("å½¢çŠ¶:", df.shape)
        st.subheader("çµ±è¨ˆæ¦‚è¦ï¼ˆæ•°å€¤åˆ—ï¼‰")
        st.dataframe(df.describe())
        st.subheader("æ¬ æå€¤ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯")
        miss = df.isnull().sum().sort_values(ascending=False).head(20)
        st.dataframe(miss[miss > 0])

# ---------------------------
# Train Model
# ---------------------------
elif page == "Train Model":
    st.title("Train Model â€” éå­¦ç¿’ LightGBM ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆSHAP ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")

    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ã“ã¡ã‚‰ã§å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾è±¡
        label_cols = ["å…šæ´¾", "å…ƒç¾æ–°", "äº‰ç‚¹1ä½", "äº‰ç‚¹2ä½", "äº‰ç‚¹3ä½", "è·æ¥­(åˆ†é¡)"]

        # ç›®çš„å¤‰æ•°
        if "å½“è½" in df.columns:
            target_col = "å½“è½"
        else:
            target_col = st.sidebar.selectbox("ç›®çš„å¤‰æ•°ã‚’é¸æŠ", df.columns)

        st.write("ç›®çš„å¤‰æ•°:", target_col)

        # ç‰¹å¾´é‡ï¼ˆã‚ãªãŸã®ãƒ¢ãƒ‡ãƒ«ã¨åŒä¸€ï¼‰
        features = [
            "å¹´é½¢", "æ€§åˆ¥", "å…šæ´¾", "å…ƒç¾æ–°", "è¡†å‚å½“é¸å›æ•°",
            "å‚è­°é™¢å½“é¸å›æ•°", "è¡†è­°é™¢å½“é¸å›æ•°", "è­°å¸­æ•°",
            "äº‰ç‚¹1ä½", "äº‰ç‚¹2ä½", "äº‰ç‚¹3ä½",
            "æ”¿åºœè¦æ¨¡", "å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°",
            "ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°", "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°",
            "è·æ¥­(åˆ†é¡)"
        ]
        features = [f for f in features if f in df.columns]

        if st.button("å­¦ç¿’é–‹å§‹ï¼ˆéå­¦ç¿’ LightGBMï¼‰"):
            with st.spinner("å‰å‡¦ç†ä¸­..."):
                df_train = df.copy()

                X = df_train[features].copy()
                y = df_train[target_col].copy()

                # å½“è½ â†’ æ•°å€¤åŒ–
                y = y.map({"å½“": 1, "è½": 0, 1: 1, 0: 0}).astype(int)

                # ============================
                # LabelEncoderï¼ˆã‚ãªãŸã®ãƒ¢ãƒ‡ãƒ«ã¨åŒä¸€ï¼‰
                # ============================
                encoders = {}
                for col in label_cols:
                    if col in X.columns:
                        le = LabelEncoder()
                        X[col] = le.fit_transform(X[col])
                        encoders[col] = le

                # ============================
                # CatBoostEncoderï¼ˆKFoldï¼‰
                # ============================
                kf = KFold(n_splits=5, shuffle=True, random_state=42)
                cbe = CatBoostEncoder()

                X_cbe = np.zeros((len(X), len(label_cols)))
                valid_cols = [c for c in label_cols if c in X.columns]

                for tr_idx, va_idx in kf.split(X):
                    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
                    y_tr = y.iloc[tr_idx]

                    cbe.fit(X_tr[valid_cols], y_tr)
                    X_cbe[va_idx, :] = cbe.transform(X_va[valid_cols]).values

                for i, col in enumerate(valid_cols):
                    X[f"{col}_cbe"] = X_cbe[:, i]

                # ============================
                # LightGBMï¼ˆéå­¦ç¿’è¨­å®šï¼‰
                # ============================
                params = {
                    "objective": "binary",
                    "metric": "binary_logloss",
                    "learning_rate": 0.01,
                    "num_leaves": 255,
                    "max_depth": -1,
                    "min_data_in_leaf": 1,
                    "feature_fraction": 1.0,
                    "bagging_fraction": 1.0,
                    "bagging_freq": 0,
                    "lambda_l1": 0.0,
                    "lambda_l2": 0.0,
                    "verbose": -1,
                    "seed": 42
                }

                train_data = lgb.Dataset(X, y)

            with st.spinner("LightGBM å­¦ç¿’ä¸­...ï¼ˆ50000ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰"):
                model = lgb.train(
                    params,
                    train_data,
                    num_boost_round=50000
                )

            # ============================
            # è©•ä¾¡ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼‰
            # ============================
            y_pred_prob = model.predict(X)
            y_pred = (y_pred_prob >= 0.5).astype(int)

            st.subheader("è©•ä¾¡ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼‰")
            st.write("æ··åŒè¡Œåˆ—")
            st.write(confusion_matrix(y, y_pred))

            st.write({
                "Accuracy": accuracy_score(y, y_pred),
                "Precision": precision_score(y, y_pred, zero_division=0),
                "Recall": recall_score(y, y_pred, zero_division=0),
                "F1": f1_score(y, y_pred, zero_division=0)
            })

            # ============================
            # ç‰¹å¾´é‡é‡è¦åº¦
            # ============================
            st.subheader("ç‰¹å¾´é‡é‡è¦åº¦")
            fig, ax = plt.subplots(figsize=(8, 10))
            lgb.plot_importance(model, ax=ax, max_num_features=30)
            st.pyplot(fig)

            # ============================
            # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            # ============================
            save_path = f"models/overfit_lgb_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            joblib.dump(
                {"model": model, "features": X.columns.tolist(), "encoders": encoders, "cbe": cbe},
                save_path
            )
            st.success(f"å­¦ç¿’å®Œäº†ï¼ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_path}")


 # -----------------------
# SHAP è¨ˆç®—ï¼†è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# -----------------------
if shap_option and SHAP_AVAILABLE:
    with st.spinner("SHAP ã‚’è¨ˆç®—ä¸­ï¼ˆãƒ‡ãƒ¼ã‚¿é‡ã«ã‚ˆã‚Šæ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ï¼‰..."):
        try:
            # X_val ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå¤§ãã„å ´åˆã¯ 500 è¡Œã«åˆ¶é™ï¼‰
            max_shap = 500
            if len(X_val) > max_shap:
                X_shap = X_val.sample(n=max_shap, random_state=42)
                st.write(f"SHAP ã¯ã‚µãƒ³ãƒ—ãƒ« {max_shap} è¡Œã§è¨ˆç®—ã—ã¾ã™ï¼ˆè¡¨ç¤ºã¯ã‚µãƒ³ãƒ—ãƒ«ï¼‰")
            else:
                X_shap = X_val

            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_shap)
            # shap_values ã®å‹ã¯ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å¤‰ã‚ã‚‹å ´åˆãŒã‚ã‚‹ã€‚ndarray ã«æƒãˆã‚‹
            if isinstance(shap_values, list):
                shap_vals_for_plot = shap_values[0]
            else:
                shap_vals_for_plot = shap_values

            # ---------- Summary Plotï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰ ----------
            st.write("### SHAP Summary Plotï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰")
            # ä½™ç™½ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«å›³ã‚’å¤§ãã‚ã«ã—ã¦å·¦ãƒãƒ¼ã‚¸ãƒ³ã‚’åºƒã’ã‚‹
            fig_summary = plt.figure(figsize=(10, 6))
            shap.summary_plot(shap_vals_for_plot, X_shap, show=False)
            # é•·ã„ç‰¹å¾´åå¯¾ç­–ã«å·¦ãƒãƒ¼ã‚¸ãƒ³ã‚’æ‹¡å¼µï¼ˆæ—¥æœ¬èªãƒ©ãƒ™ãƒ«å‘ã‘ï¼‰
            try:
                fig_summary.tight_layout()
            except Exception:
                pass
            # çµŒé¨“å‰‡çš„ã«å·¦ã‚’åºƒã’ã‚‹ï¼ˆæ—¥æœ¬èªã®é•·ã„åˆ—åãŒåˆ‡ã‚Œã‚‹ã®ã‚’é˜²ãï¼‰
            try:
                fig_summary.subplots_adjust(left=0.35)
            except Exception:
                pass
            st.pyplot(fig_summary)
            plt.close(fig_summary)

            # ---------- Bar Plotï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰ ----------
            st.write("### SHAP Bar Plotï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰")
            # ç‰¹å¾´é‡æ•°ã«å¿œã˜ã¦ç¸¦ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼ˆå¤šã„ã»ã©ç¸¦é•·ã«ï¼‰
            n_features = X_shap.shape[1] if hasattr(X_shap, "shape") else len(X_shap.columns)
            height = max(4, min(0.35 * n_features, 20))  # ä¸Šé™ã‚’ã¤ã‘ã‚‹
            fig_bar = plt.figure(figsize=(10, height))
            shap.summary_plot(shap_vals_for_plot, X_shap, plot_type="bar", show=False)
            try:
                fig_bar.tight_layout()
            except Exception:
                pass
            try:
                fig_bar.subplots_adjust(left=0.35)
            except Exception:
                pass
            st.pyplot(fig_bar)
            plt.close(fig_bar)

        except Exception as e:
            st.error(f"SHAP è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


# ---------------------------
# Candidate Prediction
# ---------------------------
elif page == "Candidate Prediction":
    st.title("Candidate Prediction â€” æ–°è¦å€™è£œã®å½“è½äºˆæ¸¬ï¼ˆSHAP ã§è¦å› åˆ†æï¼‰")

    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pkl")]
    model_files.sort(reverse=True)
    selected_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆæœ€æ–°ã‚’é¸ã¶ï¼‰", options=model_files)

    if not selected_model:
        st.info("ã¾ã å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãš Train Model ã§å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    else:
        mdl = joblib.load(os.path.join(MODEL_DIR, selected_model))
        model = mdl["model"]
        features_used = mdl["features"]
        cbe = mdl.get("cbe", None)
        label_cols = mdl.get("label_cols", [])
        label_encoders = mdl.get("label_encoders", {})

        st.write("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«:", selected_model)
        st.write("å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«å€¤ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")

        input_data = {}
        for f in features_used:
            if f.endswith("_cbe"):
                continue
            if f in ["å¹´é½¢", "è¡†å‚å½“é¸å›æ•°", "å‚è­°é™¢å½“é¸å›æ•°", "è¡†è­°é™¢å½“é¸å›æ•°", "è­°å¸­æ•°", "æ”¿åºœè¦æ¨¡"]:
                input_data[f] = st.number_input(f, value=0)
            elif f in ["æ€§åˆ¥"]:
                input_data[f] = st.selectbox(f, options=[0, 1])
            else:
                input_data[f] = st.text_input(f, value="")

        shap_individual = False
        if SHAP_AVAILABLE:
            shap_individual = st.checkbox("ã“ã®å€™è£œè€…ã® SHAP force plot ã‚’è¡¨ç¤ºã™ã‚‹ (è¦ shap)", value=False)
        else:
            st.write("â€» SHAP ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å€‹åˆ¥è¦å› ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

        if st.button("äºˆæ¸¬ã™ã‚‹"):
            X_new = pd.DataFrame([input_data])

            # LabelEncoder é©ç”¨
            for col, le in label_encoders.items():
                if col in X_new.columns:
                    try:
                        X_new[col] = le.transform(X_new[col].fillna("nan").astype(str))
                    except Exception:
                        X_new[col] = 0

            # CBE ç‰¹å¾´ä½œæˆ
            if cbe is not None and label_cols:
                for col in label_cols:
                    if col in X_new.columns:
                        try:
                            transformed = cbe.transform(X_new[[col]])
                            X_new[f"{col}_cbe"] = transformed.iloc[:, 0]
                        except Exception:
                            X_new[f"{col}_cbe"] = 0
                    else:
                        X_new[f"{col}_cbe"] = 0

            # æ•´åˆ—
            X_new = X_new.reindex(columns=[c for c in features_used if not c.endswith("_cbe")] + [c for c in features_used if c.endswith("_cbe")], fill_value=0)
            X_new = X_new.reindex(columns=features_used, fill_value=0)

            try:
                prob_arr = model.predict(X_new)
                prob = float(prob_arr[0]) if hasattr(prob_arr, "__len__") else float(prob_arr)
            except Exception as e:
                st.error(f"ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.write("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰:")
                st.dataframe(X_new)
                st.stop()

            st.metric("å½“é¸ç¢ºç‡", f"{prob:.3f}")
            st.write("é–¾å€¤0.5åˆ¤å®š:", "å½“" if prob >= 0.5 else "è½")

            # å€‹åˆ¥ SHAP è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if shap_individual and SHAP_AVAILABLE:
                try:
                    explainer = shap.TreeExplainer(model)
                    shap_values = explainer.shap_values(X_new)
                    if isinstance(shap_values, list):
                        sv = shap_values[0]
                    else:
                        sv = shap_values

                    st.subheader("ã“ã®å€™è£œè€…ã® SHAP force plotï¼ˆè¦ HTML æç”»ï¼‰")
                    # force_plot ã‚’ HTML åŒ–ã—ã¦åŸ‹ã‚è¾¼ã‚€
                    force_html = shap.force_plot(explainer.expected_value, sv, X_new, matplotlib=False)
                    components.html(force_html.html(), height=300)
                except Exception as e:
                    st.error(f"å€‹åˆ¥ SHAP ã®ä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            elif shap_individual and not SHAP_AVAILABLE:
                st.warning("SHAP ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„ãŸã‚è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

# ---------------------------
# Party / Region Analysis
# ---------------------------
elif page == "Party / Region Analysis":
    st.title("Party / Region Analysis â€” æ”¿å…šãƒ»åœ°åŸŸã®é›†è¨ˆ")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        group_by = st.selectbox(
            "ã‚°ãƒ«ãƒ¼ãƒ—åŒ–",
            options=[c for c in ["å…šæ´¾", "è­°å¸­æ•°", "åœ°åŸŸ", "é¸æŒ™åŒº"] if c in df.columns]
        )
        if st.button("é›†è¨ˆå®Ÿè¡Œ"):
            try:
                summary = df.groupby(group_by).agg({"å½“è½": ["mean", "count"]})
                summary.columns = ["å½“é¸ç¢ºç‡", "å€™è£œæ•°"]
                summary = summary.sort_values("å½“é¸ç¢ºç‡", ascending=False)
                st.dataframe(summary.head(100))
                st.bar_chart(summary["å½“é¸ç¢ºç‡"])
            except Exception as e:
                st.error(f"é›†è¨ˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ---------------------------
# Feature Analysis
# ---------------------------
elif page == "Feature Analysis":
    st.title("Feature Analysis â€” ç‰¹å¾´é‡åˆ†æ")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("å˜å¤‰é‡åˆ†å¸ƒ")
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(num_cols) == 0:
            st.info("æ•°å€¤åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        else:
            choose = st.selectbox("æ•°å€¤åˆ—ã‚’é¸æŠ", options=num_cols)
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df[choose].dropna(), kde=True, ax=ax)
            st.pyplot(fig)

        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥å½“é¸ç‡")
        cat_cols = [c for c in df.columns if (df[c].dtype == object or df[c].nunique() < 30)]
        if len(cat_cols) == 0:
            st.info("ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            chosen_cat = st.selectbox("ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’é¸ã¶", options=cat_cols)
            try:
                agg = df.groupby(chosen_cat)["å½“è½"].mean().sort_values(ascending=False)
                st.dataframe(agg)
                st.bar_chart(agg)
            except Exception as e:
                st.error(f"ã‚«ãƒ†ã‚´ãƒªåˆ¥å½“é¸ç‡ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.write(df[chosen_cat].head())
                st.write(df["å½“è½"].dtype)
                st.write(df["å½“è½"].head())

# ---------------------------
# Model Management
# ---------------------------
elif page == "Model Management":
    st.title("Model Management â€” ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
    st.write("ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§")
    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pkl")]
    model_files.sort(reverse=True)
    st.dataframe(pd.DataFrame({"model": model_files}))
    sel = st.selectbox("æ“ä½œãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", options=[""] + model_files)
    if sel:
        path = os.path.join(MODEL_DIR, sel)
        st.write("ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹:", path)
        if st.button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            with open(path, "rb") as f:
                bytes_io = io.BytesIO(f.read())
            st.download_button("Download model", data=bytes_io, file_name=sel)
        if st.button("å‰Šé™¤"):
            os.remove(path)
            st.success("å‰Šé™¤ã—ã¾ã—ãŸã€‚å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
# ---------------------------
# Newcomer Winning Patterns
# ---------------------------
elif page == "Newcomer Winning Patterns":
    st.title("Newcomer Winning Patterns â€” æ–°äººã®å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")

    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # å…ƒç¾æ–°ãƒ•ã‚£ãƒ«ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if "å…ƒç¾æ–°" not in df.columns:
        st.error("ã“ã®åˆ†æã«ã¯ 'å…ƒç¾æ–°' åˆ—ãŒå¿…è¦ã§ã™ã€‚")
        st.stop()

    # æ–°äººã ã‘æŠ½å‡º
    df_new = df[df["å…ƒç¾æ–°"].astype(str).str.strip() == "æ–°"].copy()
    if df_new.empty:
        st.error("æ–°äººãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    st.write(f"æ–°äººå€™è£œãƒ‡ãƒ¼ã‚¿æ•°: {len(df_new)} å")

    # åˆ†æå¯¾è±¡ã¨ãªã‚‹ã‚«ãƒ†ã‚´ãƒªåˆ—
    candidate_cols = [
        c for c in df_new.columns
        if (df_new[c].dtype == object or df_new[c].nunique() <= 20)
        and c not in ["å½“è½", "å…ƒç¾æ–°"]
    ]

    st.subheader("ç‰¹å¾´é‡ã”ã¨ã®æ–°äººå½“é¸ç‡ï¼ˆå˜å¤‰é‡ï¼‰")

    # å˜å¤‰é‡å½“é¸ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    result_list = []
    for col in candidate_cols:
        try:
            tmp = df_new.groupby(col)["å½“è½"].mean().sort_values(ascending=False)
            result_list.append((col, tmp))
        except:
            continue

    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤º
    for col, series in result_list:
        st.markdown(f"### ğŸ“Œ {col} åˆ¥ å½“é¸ç‡")
        st.dataframe(series)
        st.bar_chart(series)

    st.write("---")

    # å¤šå¤‰é‡ã®å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ2å¤‰é‡çµ„ã¿åˆã‚ã›ï¼‰
    st.subheader("çµ„ã¿åˆã‚ã›å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤šå¤‰é‡ï¼š2ã¤ã®ç‰¹å¾´ï¼‰")

    top_k = st.slider("è¡¨ç¤ºã™ã‚‹ä¸Šä½ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°", 5, 50, 10)

    pattern_rows = []
    for col1 in candidate_cols:
        for col2 in candidate_cols:
            if col1 >= col2:
                continue
            try:
                grp = df_new.groupby([col1, col2])["å½“è½"].mean()
                grp = grp.reset_index().sort_values("å½“è½", ascending=False)
                pattern_rows.append((f"{col1} Ã— {col2}", grp.head(top_k)))
            except:
                pass

    # è¡¨ç¤ºï¼ˆå¤šã™ãã‚‹ã®ã§ 10çµ„ã¾ã§ï¼‰
    for title, patt in pattern_rows[:10]:
        st.markdown(f"### ğŸ”¥ {title} ã®å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆTop {top_k}ï¼‰")
        st.dataframe(patt)
