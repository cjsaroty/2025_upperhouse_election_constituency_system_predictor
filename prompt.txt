以下の当落予測アプリケーションをsteamlitのアプリケーション例を参考にsteamlitアプリケーション化してください。

【当落予測アプリケーション】
import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from category_encoders import CatBoostEncoder
import lightgbm as lgb
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

plt.rcParams["font.family"] = "MS Gothic"

# ============================
# データ読み込み
# ============================
df = pd.read_excel("./Data/2025_upperhouse_election_constituency_system_cleaning.xlsx", engine="openpyxl")
df.columns = df.columns.str.strip()

rename_dict = {
    "衆参すべての当選回数": "衆参当選回数",
    "参議院の当選回数": "参議院当選回数",
    "衆議院の当選回数": "衆議院当選回数",
    "大きな政府か小さな政府か(1に近いほど小さな政府/5に近いほど大きな政府)": "政府規模",
    "出生地からの立候補か(0が出生地から立候補、1が出生地から立候補ではない)": "出生地外立候補フラグ",
    "秘書経験の有無(0が秘書経験あり、1が秘書経験なし)": "秘書経験フラグ",
    "地方議会経験の有無(0が地方議会経験あり、1が地方議会経験なし)": "地方議会経験フラグ"
}
df = df.rename(columns=rename_dict)

# ============================
# ラベルエンコード
# ============================
label_cols = ["党派", "元現新", "争点1位", "争点2位", "争点3位", "職業(分類)"]
encoders = {}
for col in label_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    encoders[col] = le

df["当落"] = df["当落"].map({"当": 1, "落": 0})

# ============================
# 特徴量セット
# ============================
features = [
    "年齢", "性別", "党派", "元現新", "衆参当選回数",
    "参議院当選回数", "衆議院当選回数", "議席数",
    "争点1位", "争点2位", "争点3位",
    "政府規模", "出生地外立候補フラグ",
    "秘書経験フラグ", "地方議会経験フラグ",
    "職業(分類)"
]

X = df[features].copy()
y = df["当落"].copy()

# ============================
# CatBoost Encoding（KFold Leak防止）
# ============================
cbe = CatBoostEncoder()
kf = KFold(n_splits=5, shuffle=True, random_state=42)

X_cbe = np.zeros((len(X), len(label_cols)))
for tr_idx, va_idx in kf.split(X):
    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
    y_tr = y.iloc[tr_idx]
    cbe.fit(X_tr[label_cols], y_tr)
    X_cbe[va_idx, :] = cbe.transform(X_va[label_cols]).values

for i, col in enumerate(label_cols):
    X[f"{col}_cbe"] = X_cbe[:, i]

# ============================
# LightGBM 過学習パラメータ設定
# ============================
params_overfit = {
    "objective": "binary",
    "metric": "binary_logloss",
    "learning_rate": 0.01,
    "num_leaves": 255,     # 木の容量最大
    "max_depth": -1,       # 深さ制限なし
    "min_data_in_leaf": 1, # 葉1サンプルで柔軟に
    "feature_fraction": 1.0,
    "bagging_fraction": 1.0,
    "bagging_freq": 0,
    "lambda_l1": 0.0,
    "lambda_l2": 0.0,
    "class_weight": None,
    "verbose": -1,
    "seed": 42
}

train_data = lgb.Dataset(X, y)

model = lgb.train(
    params_overfit,
    train_data,
    num_boost_round=50000,   # 大量のブーストで過学習
)

# ============================
# 学習データで予測
# ============================
y_pred_prob = model.predict(X)
y_pred = (y_pred_prob >= 0.5).astype(int)

# ============================
# 評価
# ============================
print("\n*** 過学習型 LightGBM 評価（学習データ） ***")
print(confusion_matrix(y, y_pred))
print(f"Accuracy : {accuracy_score(y, y_pred):.3f}")
print(f"Precision: {precision_score(y, y_pred):.3f}")
print(f"Recall   : {recall_score(y, y_pred):.3f}")
print(f"F1-score : {f1_score(y, y_pred):.3f}")

# ============================
# 特徴量重要度
# ============================
lgb.plot_importance(model, figsize=(8, 10))
plt.title("LightGBM Feature Importance (Overfit)")
plt.show()

【steamlitのアプリケーション例】
import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor


def get_model(regression_type: str):
    if regression_type == "Linear Regression":
        model = LinearRegression()
    elif regression_type == "SVM":
        model = SVR()
    else:
        model = DecisionTreeRegressor()
    return model


def main():
    st.title("機械学習アプリ")
    st.sidebar.title("設定")

    # ファイルアップロード先を表示する。
    uploaded_file = st.sidebar.file_uploader("ファイル選択", type="csv")

    # データの読み込み・学習データ作成
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        available_columns = df.columns.tolist()
        selected_columns = st.sidebar.multiselect("特徴量を選択", available_columns)
        target_column = st.sidebar.selectbox(
            "目的変数を選択", available_columns, index=len(available_columns)-1)
        test_size = st.sidebar.number_input('検証のデータの割合', min_value=0.1)
        st.write("Data shape:", df.shape)
        st.write("Data head:", df.head())

        if target_column is not None:
            X = df[selected_columns]
            y = df[target_column]

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=0)

    # アルゴリズム選択を表示する。
    regression_type = st.sidebar.selectbox("アルゴリズム選択", ["回帰分析", "SVM", "決定木"])
    model = get_model(regression_type)

    # 推論処理実行
    if st.sidebar.button("実行"):
        try:
            model.fit(X_train, y_train)
            prediction = model.predict(X_test)
            st.line_chart({'真値': y_test, '予測値': prediction})
            st.write("R2 score: ", model.score(X_test, y_test))
        except:
            st.error('設定が正しくありません。')


if __name__ == '__main__':
    main()

