# app.py
# ä¿®æ­£ç‰ˆ â€” ã€Œå½“è½ã€ãŒ object å‹ã§ groupby.mean() ãŒå¤±æ•—ã™ã‚‹å•é¡Œã‚’è§£æ¶ˆã—ã€
# å­¦ç¿’æ™‚ã®å‰å‡¦ç†ï¼ˆCBE ã§è¿½åŠ ã•ã‚ŒãŸç‰¹å¾´é‡ï¼‰ã¨äºˆæ¸¬æ™‚ã®ç‰¹å¾´åˆ—æ•´åˆæ€§ã‚’ä¿ã¤ã‚ˆã†ä¿®æ­£æ¸ˆã¿ã€‚
import streamlit as st
import pandas as pd
import numpy as np
import os
import io
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import LabelEncoder
from category_encoders import CatBoostEncoder
import lightgbm as lgb
from sklearn.metrics import (
    confusion_matrix, accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import shap

plt.rcParams["font.family"] = "MS Gothic"
sns.set_style("whitegrid")

# ---------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------
@st.cache_data
def load_excel(uploaded):
    # pandas ãŒ openpyxl ã‚’ä½¿ã£ã¦èª­ã¿è¾¼ã‚€
    return pd.read_excel(uploaded, engine="openpyxl")

def safe_rename(df):
    df = df.copy()
    df.columns = df.columns.str.strip()
    rename_dict = {
        "è¡†å‚ã™ã¹ã¦ã®å½“é¸å›æ•°": "è¡†å‚å½“é¸å›æ•°",
        "å‚è­°é™¢ã®å½“é¸å›æ•°": "å‚è­°é™¢å½“é¸å›æ•°",
        "è¡†è­°é™¢ã®å½“é¸å›æ•°": "è¡†è­°é™¢å½“é¸å›æ•°",
        "å¤§ããªæ”¿åºœã‹å°ã•ãªæ”¿åºœã‹(1ã«è¿‘ã„ã»ã©å°ã•ãªæ”¿åºœ/5ã«è¿‘ã„ã»ã©å¤§ããªæ”¿åºœ)": "æ”¿åºœè¦æ¨¡",
        "å‡ºç”Ÿåœ°ã‹ã‚‰ã®ç«‹å€™è£œã‹(0ãŒå‡ºç”Ÿåœ°ã‹ã‚‰ç«‹å€™è£œã€1ãŒå‡ºç”Ÿåœ°ã‹ã‚‰ç«‹å€™è£œã§ã¯ãªã„)": "å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°",
        "ç§˜æ›¸çµŒé¨“ã®æœ‰ç„¡(0ãŒç§˜æ›¸çµŒé¨“ã‚ã‚Šã€1ãŒç§˜æ›¸çµŒé¨“ãªã—)": "ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°",
        "åœ°æ–¹è­°ä¼šçµŒé¨“ã®æœ‰ç„¡(0ãŒåœ°æ–¹è­°ä¼šçµŒé¨“ã‚ã‚Šã€1ãŒåœ°æ–¹è­°ä¼šçµŒé¨“ãªã—)": "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°"
    }
    for k, v in rename_dict.items():
        if k in df.columns:
            df = df.rename(columns={k: v})
    return df

def coerce_target_series(y):
    """
    ç›®çš„å¤‰æ•° y ã‚’å®‰å…¨ã«æ•°å€¤åŒ–ã™ã‚‹ï¼š
    - æ—¢ã«æ•°å€¤ãªã‚‰ãã®ã¾ã¾
    - 'å½“é¸','è½é¸','å½“','è½','å½“é¸ ', 'è½é¸ ' ãªã©ã‚’ãƒãƒƒãƒ—
    - '1','0' ã®æ–‡å­—ã‚’æ•°å€¤ã«å¤‰æ›
    - True/False ã‚’ 1/0 ã«
    - ä¸Šè¨˜ã§å¤‰æ›ã§ããªã‘ã‚Œã° LabelEncoder ã‚’ä½¿ã†ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
    æˆ»ã‚Šå€¤ã¯ pandas.Seriesï¼ˆæ•°å€¤ or æ•´æ•°ï¼‰
    """
    if pd.api.types.is_numeric_dtype(y):
        return y.astype(float)

    y_ser = y.fillna("").astype(str).str.strip()

    # ä»£è¡¨çš„ãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ—
    mapping = {
        "å½“é¸": 1, "è½é¸": 0, "å½“": 1, "è½": 0,
        "åˆæ ¼": 1, "ä¸åˆæ ¼": 0,
        "win": 1, "lose": 0, "W": 1, "L": 0,
        "True": 1, "False": 0, "true": 1, "false": 0
    }

    # å°æ–‡å­—åŒ–ã‚­ãƒ¼å¯¾å¿œç­‰
    mapped = y_ser.map(mapping)
    if mapped.notnull().all():
        return mapped.astype(float)

    # ãƒãƒƒãƒ—ã§ä¸€éƒ¨ã—ã‹ç½®æ›ã•ã‚Œãªã„å ´åˆã¯ã€æ•°å€¤æ–‡å­—åˆ—ã‚’å¤‰æ›
    def try_numeric(val):
        try:
            # ä¾‹ãˆã° "1" -> 1.0, "0" -> 0.0
            return float(val)
        except:
            return np.nan

    numeric_candidate = y_ser.map(try_numeric)
    # numeric_candidate ãŒå…¨ã¦ NaN ã§ãªã‘ã‚Œã°ãã‚Œã‚’æ¡ç”¨ï¼ˆæ··åœ¨ã—ã¦ã„ã‚‹å ´åˆã¯å…ƒã® mapped ã‚’å„ªå…ˆã§ä½µåˆï¼‰
    combined = mapped.copy()
    combined[pd.isna(combined)] = numeric_candidate[pd.isna(combined)]

    if combined.notnull().all():
        return combined.astype(float)

    # ã¾ã æ··åœ¨ã—ã¦ã„ã‚‹ãªã‚‰ã€å½“/è½ãŒæ··åœ¨ã—ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã‚’å„ªå…ˆçš„ã« map ã—ã¦æ®‹ã‚Šã¯ LabelEncoder
    # æœ€å¾Œã®æ‰‹æ®µï¼šLabelEncoder
    le = LabelEncoder()
    try:
        encoded = le.fit_transform(y_ser)
        return pd.Series(encoded.astype(float), index=y_ser.index)
    except Exception:
        # æœ€çµ‚çš„ã« 0/1 ã«åˆ†ã‘ã‚‰ã‚Œãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’æŠ•ã’ã‚‹
        raise ValueError("ç›®çš„å¤‰æ•°ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚'å½“é¸/è½é¸' ãªã©ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚")

def prepare_label_encoders(df, label_cols):
    """
    LabelEncoder ã‚’å„ã‚«ãƒ†ã‚´ãƒªåˆ—ã«é©ç”¨ï¼ˆæ–‡å­—åˆ—ãƒ»ã‚«ãƒ†ã‚´ãƒªå‘ã‘ï¼‰ã€‚
    æ•°å€¤åˆ—ã«å¯¾ã—ã¦ã¯ä½•ã‚‚ã—ãªã„ã€‚
    æˆ»ã‚Šå€¤: (df_encoded, encoders_dict)
    """
    encoders = {}
    for col in label_cols:
        if col in df.columns:
            # æ•°å€¤åˆ—ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚’æ–‡å­—åˆ—ã¨ã—ã¦ãƒ©ãƒ™ãƒ«åŒ–ã—ãŸããªã„ãŸã‚ï¼‰
            if pd.api.types.is_numeric_dtype(df[col]):
                continue
            le = LabelEncoder()
            df[col] = df[col].fillna("nan").astype(str)
            df[col] = le.fit_transform(df[col])
            encoders[col] = le
    return df, encoders

def apply_cbe_kfold(X, y, label_cols, n_splits=5, random_state=42):
    """
    CatBoostEncoder ã‚’ k-fold ã§é©ç”¨ã—ã¦å„ã‚«ãƒ†ã‚´ãƒªåˆ—ã«å¯¾å¿œã™ã‚‹ *_cbe åˆ—ã‚’è¿½åŠ ã™ã‚‹ã€‚
    Xï¼ˆDataFrameï¼‰ã¯ã‚³ãƒ”ãƒ¼ã—ã¦è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: (X_with_cbe, fitted_cbe_encoder_object)
    """
    X = X.copy().reset_index(drop=True)
    y = y.reset_index(drop=True)
    # æœ‰åŠ¹ãª label_cols ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    valid_label_cols = [c for c in label_cols if c in X.columns]
    if len(valid_label_cols) == 0:
        return X, None

    cbe = CatBoostEncoder()
    kf = KFold(n_splits=max(2, int(n_splits)), shuffle=True, random_state=random_state)
    X_cbe = np.zeros((len(X), len(valid_label_cols)))

    for tr_idx, va_idx in kf.split(X):
        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
        y_tr = y.iloc[tr_idx]
        # fit on train folds
        cbe.fit(X_tr[valid_label_cols], y_tr)
        # transform validation fold
        transformed = cbe.transform(X_va[valid_label_cols])
        # transformed may be DataFrame
        X_cbe[va_idx, :] = transformed.values

    # full fit on all data for future transform
    cbe.fit(X[valid_label_cols], y)

    for i, col in enumerate(valid_label_cols):
        X[f"{col}_cbe"] = X_cbe[:, i]

    return X, cbe

# ---------------------------
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ•ã‚©ãƒ«ãƒ€
# ---------------------------
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# ---------------------------
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼
# ---------------------------
st.set_page_config(layout="wide", page_title="å½“è½äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
page = st.sidebar.radio(
    "ãƒšãƒ¼ã‚¸é¸æŠ",
    ["Overview", "Train Model", "Candidate Prediction",
     "Party / Region Analysis", "Feature Analysis", "Model Management"]
)

# ---------------------------
# å…±é€šï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ---------------------------
st.sidebar.write("---")
uploaded_file = st.sidebar.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
df = None
if uploaded_file is not None:
    df = load_excel(uploaded_file)
    df = safe_rename(df)
    # ã“ã“ã§ 'å½“è½' ãŒå­˜åœ¨ã™ã‚Œã°å¼·åˆ¶çš„ã«æ•°å€¤åŒ–ã—ã¦ãŠãï¼ˆä»¥é™ã©ã“ã§ã‚‚å®‰å…¨ã« mean() ãªã©ãŒä½¿ãˆã‚‹ï¼‰
    if "å½“è½" in df.columns:
        try:
            df["å½“è½"] = coerce_target_series(df["å½“è½"])
        except Exception as e:
            st.error(f"ç›®çš„å¤‰æ•° 'å½“è½' ã‚’æ•°å€¤åŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

# ---------------------------
# ãƒšãƒ¼ã‚¸ï¼šOverview
# ---------------------------
if page == "Overview":
    st.title("Overview â€” ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
    if df is None:
        st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df.head())
        st.write("å½¢çŠ¶:", df.shape)
        st.subheader("çµ±è¨ˆæ¦‚è¦ï¼ˆæ•°å€¤åˆ—ï¼‰")
        st.dataframe(df.describe())
        st.subheader("æ¬ æå€¤ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯")
        miss = df.isnull().sum().sort_values(ascending=False).head(20)
        st.dataframe(miss[miss > 0])

# ---------------------------
# ãƒšãƒ¼ã‚¸ï¼šTrain Model
# ---------------------------
elif page == "Train Model":
    st.title("Train Model â€” ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ã“ã¡ã‚‰ã§å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    else:

        # ğŸ”¥ ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼šLabelEncoder é©ç”¨å¯¾è±¡ã« 3 ã¤ã®ãƒ•ãƒ©ã‚°åˆ—ã‚’è¿½åŠ 
        label_cols = [
            c for c in [
                "å…šæ´¾", "å…ƒç¾æ–°", "äº‰ç‚¹1ä½", "äº‰ç‚¹2ä½", "äº‰ç‚¹3ä½",
                "è·æ¥­(åˆ†é¡)", "å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°",
                "ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°", "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°"
            ]
            if c in df.columns
        ]

        # ç›®çš„å¤‰æ•°
        if "å½“è½" in df.columns:
            default_index = list(df.columns).index("å½“è½")
        else:
            default_index = 0

        target_col = st.sidebar.selectbox(
            "ç›®çš„å¤‰æ•°ã‚’é¸æŠ",
            options=[c for c in df.columns],
            index=default_index
        )

        st.write("ç›®çš„å¤‰æ•°:", target_col)

        # ç‰¹å¾´é‡é¸æŠ
        features = st.multiselect(
            "ç‰¹å¾´é‡ã‚’é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å¥¨ï¼‰",
            options=[c for c in df.columns if c != target_col],
            default=[c for c in [
                "å¹´é½¢","æ€§åˆ¥","å…šæ´¾","å…ƒç¾æ–°","è¡†å‚å½“é¸å›æ•°","å‚è­°é™¢å½“é¸å›æ•°",
                "è¡†è­°é™¢å½“é¸å›æ•°","è­°å¸­æ•°","äº‰ç‚¹1ä½","äº‰ç‚¹2ä½","äº‰ç‚¹3ä½",
                "æ”¿åºœè¦æ¨¡","å‡ºç”Ÿåœ°å¤–ç«‹å€™è£œãƒ•ãƒ©ã‚°","ç§˜æ›¸çµŒé¨“ãƒ•ãƒ©ã‚°",
                "åœ°æ–¹è­°ä¼šçµŒé¨“ãƒ•ãƒ©ã‚°","è·æ¥­(åˆ†é¡)"
            ] if c in df.columns]
        )

        test_size = st.sidebar.slider("æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿å‰²åˆï¼ˆtest_sizeï¼‰", 0.1, 0.5, 0.2)

        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        st.sidebar.write("LightGBM ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        lr = st.sidebar.number_input("learning_rate", min_value=0.0001, max_value=0.5,
                                     value=0.05, format="%.4f")
        num_leaves = st.sidebar.slider("num_leaves", 8, 512, 64)
        n_estimators = st.sidebar.number_input(
            "num_boost_round æœ€å¤§",
            min_value=100, max_value=100000,
            value=5000, step=100
        )
        early_stopping_rounds = st.sidebar.number_input(
            "early_stopping_rounds",
            min_value=10, max_value=1000, value=100
        )
        val_frac_for_cbe = st.sidebar.slider("CBE ç”¨ kfold åˆ†å‰²æ•°", 3, 10, 5)

        if st.button("å‰å‡¦ç†ï¼†å­¦ç¿’ã‚’å®Ÿè¡Œ"):
            with st.spinner("å‰å‡¦ç†ä¸­..."):
                X = df[features].copy()
                y = df[target_col].copy()

                # ç›®çš„å¤‰æ•°ã‚’å®‰å…¨ã«æ•°å€¤åŒ–
                try:
                    y = coerce_target_series(y)
                except Exception as e:
                    st.error(f"ç›®çš„å¤‰æ•°ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    st.stop()

                # LabelEncoder é©ç”¨ï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ—ã®ã¿ï¼‰
                X, encoders = prepare_label_encoders(X, label_cols)

                # CBEï¼ˆk-foldï¼‰ã§ã‚«ãƒ†ã‚´ãƒªç‰¹å¾´ã‚’æ•°å€¤åŒ–ã—ã¦ *_cbe åˆ—ã‚’è¿½åŠ 
                X, cbe = apply_cbe_kfold(X, y, label_cols, n_splits=val_frac_for_cbe)

                # å­¦ç¿’ã«ä½¿ã†æœ€çµ‚çš„ãªç‰¹å¾´åˆ—ï¼ˆCBE ã§è¿½åŠ ã•ã‚ŒãŸåˆ—ã‚‚å«ã‚ã‚‹ï¼‰
                features_used = X.columns.tolist()

                # split
                try:
                    X_train, X_val, y_train, y_val = train_test_split(
                        X, y, test_size=test_size, stratify=y, random_state=42
                    )
                except Exception as e:
                    st.error(f"train_test_split ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆstratify å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼‰: {e}")
                    st.stop()

                # LightGBM dataset
                train_data = lgb.Dataset(X_train, label=y_train)
                valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

                params = {
                    "objective": "binary",
                    "metric": "binary_logloss",
                    "learning_rate": lr,
                    "num_leaves": num_leaves,
                    "verbose": -1,
                    "seed": 42
                }

            with st.spinner("LightGBM å­¦ç¿’ä¸­..."):
                # å­¦ç¿’ï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ã§ early stoppingï¼‰
                model = lgb.train(
                    params,
                    train_data,
                    num_boost_round=int(n_estimators),
                    valid_sets=[valid_data],
                    callbacks=[
                        lgb.early_stopping(stopping_rounds=int(early_stopping_rounds)),
                        lgb.log_evaluation(period=50)
                    ]
                )

            # è©•ä¾¡
            y_val_pred_prob = model.predict(X_val)
            y_val_pred = (y_val_pred_prob >= 0.5).astype(int)
            st.subheader("è©•ä¾¡ï¼ˆæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
            st.write("æ··åŒè¡Œåˆ—")
            st.write(confusion_matrix(y_val, y_val_pred))
            st.write({
                "Accuracy": accuracy_score(y_val, y_val_pred),
                "Precision": precision_score(y_val, y_val_pred, zero_division=0),
                "Recall": recall_score(y_val, y_val_pred, zero_division=0),
                "F1": f1_score(y_val, y_val_pred, zero_division=0),
                "ROC_AUC": roc_auc_score(y_val, y_val_pred_prob)
            })

            # ä¿å­˜ï¼ˆãƒ¢ãƒ‡ãƒ« + å‰å‡¦ç†æƒ…å ±ã‚’ä¿å­˜ï¼‰
            model_name = f"lgb_model_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.pkl"
            save_obj = {
                "model": model,
                # ä¿å­˜ã™ã‚‹ç‰¹å¾´é‡ã¯ã€Œå®Ÿéš›ã«å­¦ç¿’ã«æ¸¡ã—ãŸåˆ—ã€ã‚’ä¿å­˜ï¼ˆCBE åˆ—ã‚’å«ã‚€ï¼‰
                "features": features_used,
                "cbe": cbe,
                "label_cols": label_cols,
                "label_encoders": encoders
            }
            joblib.dump(save_obj, os.path.join(MODEL_DIR, model_name))
            st.success(f"å­¦ç¿’å®Œäº†ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_name}")
            st.session_state["latest_model_path"] = os.path.join(MODEL_DIR, model_name)

# ---------------------------
# ãƒšãƒ¼ã‚¸ï¼šCandidate Prediction
# ---------------------------
elif page == "Candidate Prediction":
    st.title("Candidate Prediction â€” æ–°è¦å€™è£œã®å½“è½äºˆæ¸¬")

    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pkl")]
    model_files.sort(reverse=True)
    selected_model = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆæœ€æ–°ã‚’é¸ã¶ï¼‰", options=model_files)

    if not selected_model:
        st.info("ã¾ã å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãš Train Model ã§å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    else:
        mdl = joblib.load(os.path.join(MODEL_DIR, selected_model))
        model = mdl["model"]
        features_used = mdl["features"]  # ã“ã“ã¯å­¦ç¿’æ™‚ã«ä¿å­˜ã—ãŸå®Ÿéš›ã®ç‰¹å¾´åˆ—
        cbe = mdl.get("cbe", None)
        label_cols = mdl.get("label_cols", [])
        label_encoders = mdl.get("label_encoders", {})

        st.write("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«:", selected_model)
        st.write("å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã«å€¤ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")

        # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ä½œæˆï¼ˆå­¦ç¿’æ™‚ã®å…ƒã®ç‰¹å¾´åˆ—åãŒã‚ã‹ã‚‰ãªã„å ´åˆã«å‚™ãˆã€
        # æ•°å€¤ã£ã½ã„åå‰ã¯ number_inputã€'æ€§åˆ¥' ãªã©ã¯ selectboxã€ãã®ä»–ã¯ text_input ã‚’ä½¿ã†ï¼‰
        input_data = {}
        # å­¦ç¿’æ™‚ã«ä½¿ã£ãŸç‰¹å¾´åˆ—ãŒå¤šã„å ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ ãŒé•·ããªã‚‹ç‚¹ã«æ³¨æ„
        for f in features_used:
            # skip CBE columns (these are generated automatically)
            if f.endswith("_cbe"):
                # ç”Ÿæˆã¯ãƒ¢ãƒ‡ãƒ«å´ã§è¡Œã†ã®ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¯ä¸è¦ â€” å¾Œã§åˆ¥é€”ä½œæˆ
                continue
            if f in ["å¹´é½¢", "è¡†å‚å½“é¸å›æ•°", "å‚è­°é™¢å½“é¸å›æ•°", "è¡†è­°é™¢å½“é¸å›æ•°", "è­°å¸­æ•°", "æ”¿åºœè¦æ¨¡"]:
                input_data[f] = st.number_input(f, value=0)
            elif f in ["æ€§åˆ¥"]:
                input_data[f] = st.selectbox(f, options=[0, 1])
            else:
                input_data[f] = st.text_input(f, value="")

        if st.button("äºˆæ¸¬ã™ã‚‹"):
            # DataFrame ã‚’ä½œã‚‹
            X_new = pd.DataFrame([input_data])

            # LabelEncoder ã‚’é©ç”¨ï¼ˆå­¦ç¿’æ™‚ã«ç”¨ã„ãŸ encoders ã«åˆã‚ã›ã‚‹ï¼‰
            for col, le in label_encoders.items():
                if col in X_new.columns:
                    try:
                        X_new[col] = le.transform(X_new[col].fillna("nan").astype(str))
                    except Exception:
                        # å­¦ç¿’æ™‚ã«è¦‹ãŸã‚«ãƒ†ã‚´ãƒªã§ãªã„å ´åˆã¯ -1 ã‚’å…¥ã‚Œã¦ãŠãï¼ˆã¾ãŸã¯ 0ï¼‰
                        X_new[col] = 0

            # CBE ç‰¹å¾´ä½œæˆï¼ˆå­¦ç¿’æ™‚ã« fit ã—ãŸ cbe ãŒã‚ã‚Œã° transformï¼‰
            if cbe is not None and label_cols:
                for col in label_cols:
                    if col in X_new.columns:
                        try:
                            # cbe.transform expects DataFrame with label cols
                            transformed = cbe.transform(X_new[[col]])
                            X_new[f"{col}_cbe"] = transformed.iloc[:, 0]
                        except Exception:
                            X_new[f"{col}_cbe"] = 0
                    else:
                        # æ¬ ã‘ã¦ã„ã‚‹åˆ—ã¯ 0 ã§åŸ‹ã‚ã‚‹
                        X_new[f"{col}_cbe"] = 0

            # æœ€çµ‚çš„ã«ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹åˆ—é †ã«æ•´ãˆã€è¶³ã‚Šãªã„åˆ—ã¯ 0 ã§è£œå®Œ
            X_new = X_new.reindex(columns=[c for c in features_used if not c.endswith("_cbe")] + [c for c in features_used if c.endswith("_cbe")], fill_value=0)
            # æ³¨æ„: ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’æ™‚ã« features_used ã®é †ã§å­¦ç¿’ã—ã¦ã„ã‚‹ã¯ãšãªã®ã§ã€ãã®é †ã‚’ç¶­æŒã—ã¦æ¸¡ã™
            X_new = X_new.reindex(columns=features_used, fill_value=0)

            # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã¯ predict ãŒ (n_samples,) ã§ã¯ãªã (n_samples,1) ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŒä¸€èˆ¬çš„ã«ã¯ (n,)
            try:
                prob = model.predict(X_new)[0]
            except Exception as e:
                st.error(f"ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                st.write("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰:")
                st.dataframe(X_new)
                st.stop()

            st.metric("å½“é¸ç¢ºç‡", f"{prob:.3f}")
            st.write("é–¾å€¤0.5åˆ¤å®š:", "å½“" if prob >= 0.5 else "è½")

# ---------------------------
# ãƒšãƒ¼ã‚¸ï¼šParty / Region Analysis
# ---------------------------
elif page == "Party / Region Analysis":
    st.title("Party / Region Analysis â€” æ”¿å…šãƒ»åœ°åŸŸã®é›†è¨ˆ")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        group_by = st.selectbox(
            "ã‚°ãƒ«ãƒ¼ãƒ—åŒ–",
            options=[c for c in ["å…šæ´¾", "è­°å¸­æ•°", "åœ°åŸŸ", "é¸æŒ™åŒº"] if c in df.columns]
        )
        if st.button("é›†è¨ˆå®Ÿè¡Œ"):
            # å½“è½ãŒæ•°å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ä¿è¨¼ï¼ˆOverview ã®èª­ã¿è¾¼ã¿æ™‚ç‚¹ã§ coerce ã—ã¦ã„ã‚‹ã¯ãšï¼‰
            try:
                summary = df.groupby(group_by).agg({"å½“è½": ["mean", "count"]})
                summary.columns = ["å½“é¸ç¢ºç‡", "å€™è£œæ•°"]
                summary = summary.sort_values("å½“é¸ç¢ºç‡", ascending=False)
                st.dataframe(summary.head(100))
                st.bar_chart(summary["å½“é¸ç¢ºç‡"])
            except Exception as e:
                st.error(f"é›†è¨ˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ---------------------------
# ãƒšãƒ¼ã‚¸ï¼šFeature Analysis
# ---------------------------
elif page == "Feature Analysis":
    st.title("Feature Analysis â€” ç‰¹å¾´é‡åˆ†æ")
    if df is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.subheader("å˜å¤‰é‡åˆ†å¸ƒ")
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if len(num_cols) == 0:
            st.info("æ•°å€¤åˆ—ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        else:
            choose = st.selectbox("æ•°å€¤åˆ—ã‚’é¸æŠ", options=num_cols)
            fig, ax = plt.subplots(figsize=(8, 4))
            sns.histplot(df[choose].dropna(), kde=True, ax=ax)
            st.pyplot(fig)

        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥å½“é¸ç‡")
        # ã‚«ãƒ†ã‚´ãƒªåˆ—ã®åˆ¤å®šã‚’å³å¯†ã«ï¼ˆobject ã¾ãŸã¯ unique < 30ï¼‰
        cat_cols = [c for c in df.columns if (df[c].dtype == object or df[c].nunique() < 30)]
        if len(cat_cols) == 0:
            st.info("ã‚«ãƒ†ã‚´ãƒªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            chosen_cat = st.selectbox("ã‚«ãƒ†ã‚´ãƒªåˆ—ã‚’é¸ã¶", options=cat_cols)
            try:
                # å½“è½ãŒæ•°å€¤ã§ã‚ã‚‹ã“ã¨ã‚’å‰æã« mean ã‚’ã¨ã‚‹ï¼ˆcoerce ã—ã¦ã„ã‚Œã°å®‰å…¨ï¼‰
                agg = df.groupby(chosen_cat)["å½“è½"].mean().sort_values(ascending=False)
                st.dataframe(agg)
                st.bar_chart(agg)
            except Exception as e:
                st.error(f"ã‚«ãƒ†ã‚´ãƒªåˆ¥å½“é¸ç‡ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.write("é¸æŠåˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã¨ã‚µãƒ³ãƒ—ãƒ«:")
                st.write(df[chosen_cat].head())
                st.write("å½“è½åˆ—ã®å‹ãƒ»ã‚µãƒ³ãƒ—ãƒ«:")
                st.write(df["å½“è½"].dtype)
                st.write(df["å½“è½"].head())

# ---------------------------
# ãƒšãƒ¼ã‚¸ï¼šModel Management
# ---------------------------
elif page == "Model Management":
    st.title("Model Management â€” ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
    st.write("ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§")
    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pkl")]
    model_files.sort(reverse=True)
    st.dataframe(pd.DataFrame({"model": model_files}))
    sel = st.selectbox("æ“ä½œãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ", options=[""] + model_files)
    if sel:
        path = os.path.join(MODEL_DIR, sel)
        st.write("ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹:", path)
        if st.button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            with open(path, "rb") as f:
                bytes_io = io.BytesIO(f.read())
            st.download_button("Download model", data=bytes_io, file_name=sel)
        if st.button("å‰Šé™¤"):
            os.remove(path)
            st.success("å‰Šé™¤ã—ã¾ã—ãŸã€‚å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
